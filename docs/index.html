<!DOCTYPE html>
<html lang="en">
<head lang="en">
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FV0RC59Q5E"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-FV0RC59Q5E');
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>FreNBRDF: A Frequency-Rectified Neural Material Representation</title>

     <!-- mirror: F0%9F%AA%9E&lt -->
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/app.css">
</head>

<body>
<div class="container" id="header" style="text-align: center; margin: auto;">
    <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
        <h2 class="col-md-12 text-center">
            <b>FreNBRDF: A Frequency-Rectified<br>Neural Material Representation</b><br>
            <small>
                IEEE MLSP 2025
            </small>
        </h2>
    </div>
    <div class="row" id="author-row" style="margin:0 auto;">
        <!-- <div class="col-md-12 text-center" style="display: table; margin:0 auto"> -->
        <div class="text-center" style="display: table; margin:0 auto">
            <a href="https://chenliang-zhou.github.io" style="font-size: 18px;">Chenliang Zhou</a>†, <a href="https://peterhuistyping.github.io/" style="font-size: 18px;">Zheyuan Hu</a>†, <a href="https://www.cl.cam.ac.uk/~aco41/" style="font-size: 18px;">Cengiz Öztireli</a>.
            <br>
            <a href="https://www.cst.cam.ac.uk/ " style="font-size: 14px;">Department of Computer Science and Technology</a>,
            <br>
            <a href="https://www.cam.ac.uk/" style="font-size: 15px;">University of Cambridge</a>.
            <br>
            <small>† denotes equal contribution.</small>
            <br><br>
        </div>
    </div>
</div>
<script>
    document.getElementById('author-row').style.maxWidth = document.getElementById("title-row").clientWidth + 'px';
</script>
<div class="container" id="main">
    <div class="row">
        <div class="col-md-3 col-md-offset-3 text-center">
            <ul class="nav nav-pills nav-justified">
                <li>
                    <a href="https://arxiv.org/pdf/2507.00476">
                        <img src="./img/icon/paper_icon.png" alt="paper icon" height="70px">
                        <h4><strong>PDF</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="https://github.com/PeterHUistyping/FreNBRDF">
                        <img alt="github icon" src="./img/icon/github_icon.svg" height="70px">
                        <h4><strong>Github</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="https://arxiv.org/abs/2507.00476">
                        <img src="./img/icon/paper_icon.png" alt="paper icon" height="70px">
                        <h4><strong>Paper</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="https://youtu.be/K5EP7n452Mo?si=yhBMt55nq0HCvDgD">
                    <!-- bilibili: https://www.bilibili.com/video/BV1FmbszbEdh/?share_source=copy_web&vd_source=ce5833100e3b217659263210a593a51f -->
                    <img src="./img/icon/video_icon.png" height="90px">
                        <h4><strong>Video</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="https://cdfg.csail.mit.edu/wojciech/brdfdatabase/">
                    <img src="./img/icon/data_icon.webp" height="90px">
                        <h4><strong>MERL dataset (100)</strong></h4>
                    </a>
                </li>
            </ul>
        </div>

    </div>

    <div style="text-align: center;">
    <!-- Video player -->
        <iframe 
            id="videoFrame" 
            width="560" 
            height="315" 
            src="https://www.youtube.com/embed/K5EP7n452Mo?si=q9zdiyeemovJ3CFm" 
            title="Video player" 
            frameborder="0" 
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
            referrerpolicy="strict-origin-when-cross-origin" 
            allowfullscreen>
        </iframe>
        <br>
        <!-- Switch Button -->
        <button id="switchBtn" onclick="switchVideo()" style="margin-top: 10px; padding: 2px 2px; font-size: 12px;">
            Switch to Bilibili
        </button>
    </div>

    <script>
        let currentVideo = 0;
        const videos = [
            "https://www.youtube.com/embed/K5EP7n452Mo?si=q9zdiyeemovJ3CFm",
            "https://player.bilibili.com/player.html?isOutside=true&aid=115033585488961&bvid=BV1FmbszbEdh&cid=31721785214&p=1"
        ];

        function switchVideo() {
            currentVideo = 1 - currentVideo; // toggles between 0 and 1
            document.getElementById("videoFrame").src = videos[currentVideo];
            
            // Change button text based on current video
            document.getElementById("switchBtn").textContent = 
                currentVideo === 0 ? "Switch to Bilibili" : "Switch to YouTube";
        }
    </script>
 

    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                Abstract
            </h3>
            <p class="text-justify">
                Accurate material modeling is crucial for achieving photorealistic rendering, bridging the gap between computer-generated imagery and real-world photographs. While traditional approaches rely on tabulated BRDF data, recent work has shifted towards implicit neural representations, which offer compact and flexible frameworks for a range of tasks. However, their behavior in the frequency domain remains poorly understood.  <br/>
                To address this, we introduce <i>FreNBRDF</i>, a frequency-rectified neural material representation. By leveraging spherical harmonics, we integrate frequency-domain considerations into neural BRDF modeling. We propose a novel <i>frequency-rectified loss</i>, derived from a frequency analysis of neural materials, and incorporate it into a generalizable and adaptive reconstruction and editing pipeline. This framework enhances fidelity, adaptability, and efficiency. <br/>
                Extensive experiments demonstrate that FreNBRDF improves the accuracy and robustness of material appearance reconstruction and editing compared to state-of-the-art baselines, enabling more structured and interpretable downstream tasks and applications.
            </p>
        </div>
    </div>

    <img src="img/teaser.jpg" class="img-responsive" alt="Overview" width="60%"
         style="max-height: 450px;margin:auto;"/>
    <div style="text-align: center;">
        <figcaption>Overview of FreNBRDF architecture.</figcaption>
    </div>

    <div class="row">
        <div class="col-md-8 col-md-offset-2">

            <h3>
               Main methodology
            </h3>

            For the network, we adopt a set encoder [21] with permutation invariance and flexibility of input size. It takes an arbitrary set of samples as input, which is the concatenation of BRDF values and coordinates, containing four fully connected layers with two hidden layers of 128 hidden neurons and ReLU activation function. 
            <br/>
            
            The <b>reconstruction loss</b> between two NBRDFs is defined to be the sum of the L1 loss between samples of the two underlying BRDFs and the two regularization terms for NBRDF weights w and latent embeddings z.

            <figure>
                <div style="text-align: center;">
                    <img src="img/math.png" class="img-responsive" alt="math" width="100%" />
                    <!--  style="max-height: 450px;margin:auto;" -->
                </div>
                <figcaption>
                    A summary of the main methodology, i.e. how Frequency-Rectified Neural BRDFs are constructed and optimized based on prior work.
                </figcaption>
            </figure>
            
            <b>Frequency Recitification</b> The key insight here is that these frequency coefficients now contain the extracted frequency information at each degree l and order m. Therefore, we can define a frequency-rectified loss on BRDFs based on the mean squared error of frequency coefficients and consequently, we can incorporate this loss into the reconstruction loss Eq. (1).

            <h3>
              BRDF datasets and codebases references
            </h3>
            
            Inspired by prior work <a href="https://github.com/Chenliang-Zhou/FrePolad">FrePolad (ECCV'24)</a>, <a href="https://github.com/faziletgokbudak/HyperBRDF">HyperBRDF (ECCV'24)</a> and <a href="https://arxiv.org/abs/2411.12015">NeuMaDiff</a>, we adopt MERL (2003) from <a href="https://cdfg.csail.mit.edu/wojciech/brdfdatabase/">here</a>, which contains reflectance functions of 100 different materials, as our main dataset. This dataset is ideal due to its diversity and data-driven nature, making it suitable for both statistical and neural-network-based methods. <br/>

            It contains 100 measured real-world materials. Each BRDF is represented as a 90 × 90 × 180 × 3 floating-point array, mapping uniformly sampled input angles (θ_H , θ_D , ϕ_D) under Rusinkiewicz reparametrization to reflectance values in R^3.
   
            
            <h3>
                Reconstructed Materials
            </h3>

            We present 30 reconstructed materials rendered under consistent scene and lighting conditions in the below figure. The results demonstrate that FreNBRDF effectively learns the material distribution and produces high-quality, faithful reconstructions. 

            <figure>
                <div style="text-align: center;">
                    <img src="img/vis-reconstruction.png" class="img-responsive" alt="vis-reconstruction" width="100%" />
                    <!--  style="max-height: 450px;margin:auto;" -->
                </div>
                <figcaption>
                    FreNBRDF reconstructs 30 MERL materials with high quality, indicating that FreNBRDF effectively learns the material distribution (ground truths to the left and the reconstructed material to the right).
                </figcaption>
            </figure>


            In Tab. 1, we compare the performance of FreNBRDF on the material reconstruction task with two state-of-the-art baselines: the method of Gokbudak et al. [6] and a naive NBRDF [4] reconstruction pipeline, as described in Sec. 3.1, without frequency rectification. From the results, we can see that FreNBRDF outperforms both baselines across most metrics evaluating frequency compliance, rendering quality, and visual similarity, confirming the effectiveness of our proposed approach. Note that the higher RMSE score for FreNBRDF is likely due to its reconstruction loss (Eq. 11) being designed to enforce consistency in both the spatial and frequency domains.

            <figure>
                <div style="text-align: center;">
                    <img src="img/tbl.png" class="img-responsive" alt="tbl-both" width="100%" />
                    <!--  style="max-height: 450px;margin:auto;" -->
                </div>
                <figcaption>
                    Quantitative comparison of FreNBRDF with state-of-the-art baselines.
                </figcaption>
            </figure>


            <h3>
                Material editing
            </h3>

            Our pipeline provides a low-dimensional space of neural materials, enabling material editing by linearly interpolating between embeddings of different materials. We compare different models on this task. The ground truth can be obtained by directly linearly interpolating the MERL materials [3]. The below figure illustrates interpolations between five pairs of MERL materials where each row represents one interpolation.

            <figure>
                <div style="text-align: center;">
                    <img src="img/vis-editing.png" class="img-responsive" alt="vis-editing" width="100%" />
                    <!--  style="max-height: 450px;margin:auto;" -->
                </div>
                <figcaption>
                    FreNBRDF reconstructs 30 MERL materials with high quality, indicating that FreNBRDF effectively learns the material distribution (ground truths to the left and the reconstructed material to the right).
                </figcaption>
            </figure>

            <br />
            The smooth transitions between the two endpoints demonstrate the capability of our FreNBRDF as a robust and effective implicit neural representation for materials. We also report the relevant metrics in Tab. 2 (above), computed over 2000 randomly interpolated materials. The results show that materials represented by FreNBRDF exhibit consistently higher quality compared to the two baselines. 
            <br />
            Compared to the reconstruction results in Tab. 1, the interpolated materials produced by the two baselines show degraded performance, while those generated by FreNBRDF maintain similar quality. This indicates that FreNBRDF effectively captures the underlying distribution of neural materials.

        </div>
    </div>

    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            
          

            
        <!-- <div class="row" id="bibtex"> -->
            <!-- <div class="col-md-8 col-md-offset-2"> -->
                <h3>
                    Citation  
                </h3>
                If you found the paper or code useful, please consider citing, <br/>
<pre><code>@misc{zhou2025FreNBRDF,
      title={FreNBRDF: A Frequency-Rectified Neural Material Representation}, 
      author={Chenliang Zhou and Zheyuan Hu and Cengiz Oztireli},
      year={2025},
      eprint={2507.00476},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2507.00476}, 
}</code></pre>
            <!-- </div> -->
        <!-- </div> -->
            
        <br><br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <p class="text-justify">
                    The website template was inspired by <a href="https://chenliang-zhou.github.io/FrePolad/">FrePolad</a>.
                </p>
            </div>
        </div>
    </div>
</div>

</body>
</html>
